model,lambda_reg,epoch,train_loss,test_loss,test_accuracy,test_precision,test_recall,test_f1
roberta,0.75,1,0.0466626660323143,,,,,
roberta,0.75,2,0.0746219569015503,,,,,
roberta,0.75,3,0.13390260392189027,,,,,
roberta,0.75,4,0.1461004130268097,,,,,
roberta,0.75,5,0.2077367913389206,,,,,
roberta,0.75,final_test,,0.2600085366638264,0.89552,0.8859484777517564,0.90792,0.8967996839193995
roberta,1,1,0.18047917655706405,,,,,
roberta,1,2,0.28924587703704835,,,,,
roberta,1,3,0.34664792404413225,,,,,
roberta,1,4,0.6530733653080464,,,,,
roberta,1,5,0.4810463329899311,,,,,
roberta,1,final_test,,0.29351338605046084,0.88312,0.8578687789568077,0.9184,0.8871030059500812
roberta,2,1,0.5866887344110012,,,,,
roberta,2,2,0.9631985612082481,,,,,
roberta,2,3,1.6290342659497261,,,,,
roberta,2,4,1.6564530677986145,,,,,
roberta,2,5,1.410648580133915,,,,,
roberta,2,final_test,,0.47192995515697433,0.82868,0.7662842698813922,0.94584,0.8466468545239716
